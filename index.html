<!doctype html>
<html lang="fr">
<head>
  <meta charset="utf-8" />
  <title>Scan photo — Déverrouillage (Jeu)</title>
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <style>
    body { font-family: Arial, Helvetica, sans-serif; display:flex; flex-direction:column; align-items:center; padding:20px; }
    #video { width:360px; height:480px; background:#000; border:1px solid #333; }
    #refImg { max-width:220px; margin-top:12px; border:1px solid #ccc; }
    #status { margin-top:12px; font-weight:600; color:#222;}
    #controls { margin-top:10px; }
    button { padding:8px 12px; font-size:16px; margin-right:8px; }
    footer { margin-top:18px; font-size:13px; color:#555; max-width:720px; text-align:center; }
  </style>
</head>
<body>
  <h2>Scanner la photo (Face-ID simulé)</h2>

  <video id="video" autoplay muted></video>
  <div id="controls">
    <button id="startBtn">Démarrer la caméra</button>
    <button id="scanBtn" disabled>Scanner maintenant</button>
    <button id="stopBtn" disabled>Arrêter</button>
  </div>

  <<img id="refImg" src="camille.png" alt="Photo de référence (placez-la devant l'objectif)" />
 />
  <div id="status">Statut : prêt. Chargez la caméra et placez la photo devant l'objectif.</div>

  <!-- face-api CDN (vladmandic builds) -->
  <script defer src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.min.js"></script>

  <script>
    const MODEL_URL = 'https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/';
    const video = document.getElementById('video');
    const startBtn = document.getElementById('startBtn');
    const scanBtn = document.getElementById('scanBtn');
    const stopBtn = document.getElementById('stopBtn');
    const statusEl = document.getElementById('status');
    const refImgEl = document.getElementById('refImg');

    let referenceDescriptor = null;
    let stream = null;
    const THRESHOLD = 0.6; // ajustable (plus bas = plus strict)

    async function loadModels() {
      statusEl.textContent = 'Chargement des modèles...';
      await faceapi.nets.ssdMobilenetv1.loadFromUri(MODEL_URL);
      await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
      await faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL);
      statusEl.textContent = 'Modèles chargés.';
    }

    async function computeReferenceDescriptor() {
      statusEl.textContent = 'Traitement de la photo de référence...';
      await refImgEl.decode();
      const detections = await faceapi.detectSingleFace(refImgEl).withFaceLandmarks().withFaceDescriptor();
      if (!detections) {
        statusEl.textContent = 'Aucun visage détecté sur la photo de référence. Recadre la photo sur le visage.';
        throw new Error('No face in reference image');
      }
      referenceDescriptor = detections.descriptor;
      statusEl.textContent = 'Photo de référence prête. Démarre la caméra.';
      scanBtn.disabled = false;
    }

    async function startCamera() {
      try {
        stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" }, audio: false });
        video.srcObject = stream;
        await video.play();
        statusEl.textContent = 'Caméra activée. Place la photo devant l\'objectif puis clique "Scanner maintenant".';
        scanBtn.disabled = false;
        stopBtn.disabled = false;
      } catch (err) {
        statusEl.textContent = 'Erreur caméra : ' + (err.message || err);
      }
    }

    async function captureFrameDescriptor() {
      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth || 640;
      canvas.height = video.videoHeight || 480;
      const ctx = canvas.getContext('2d');
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      const detection = await faceapi.detectSingleFace(canvas).withFaceLandmarks().withFaceDescriptor();
      return detection ? detection.descriptor : null;
    }

    function euclideanDistance(d1, d2) {
      let sum = 0;
      for (let i = 0; i < d1.length; i++) {
        const diff = d1[i] - d2[i];
        sum += diff * diff;
      }
      return Math.sqrt(sum);
    }

    async function scanAndCompare() {
      statusEl.textContent = 'Scan en cours — place la photo devant l\'objectif...';
      let bestDistance = Infinity;
      for (let i = 0; i < 3; i++) {
        const desc = await captureFrameDescriptor();
        if (desc) {
          const dist = euclideanDistance(referenceDescriptor, desc);
          if (dist < bestDistance) bestDistance = dist;
        }
        await new Promise(r => setTimeout(r, 350));
      }

      if (bestDistance === Infinity) {
        statusEl.textContent = 'Aucun visage détecté. Ajuste la position / la luminosité et réessaie.';
        return;
      }

      statusEl.textContent = 'Meilleure distance : ' + bestDistance.toFixed(3);
      if (bestDistance <= THRESHOLD) {
        statusEl.textContent = 'Déverrouillage réussi ! Redirection...';
        if (stream) { stream.getTracks().forEach(t => t.stop()); }
        setTimeout(() => { window.location.href = 'unlocked.html'; }, 900);
      } else {
        statusEl.textContent = 'Échec du scan (photo non reconnue). Essaie un meilleur alignement.';
      }
    }

    function stopCamera() {
      if (stream) { stream.getTracks().forEach(t => t.stop()); }
      video.srcObject = null;
      statusEl.textContent = 'Caméra arrêtée.';
      stopBtn.disabled = true;
    }

    (async () => {
      await loadModels();
      refImgEl.addEventListener('load', async () => {
        try { await computeReferenceDescriptor(); } catch(e) { console.error(e); }
      });
      if (refImgEl.complete) {
        try { await computeReferenceDescriptor(); } catch(e) { console.error(e); }
      }
    })();

    startBtn.addEventListener('click', startCamera);
    scanBtn.addEventListener('click', scanAndCompare);
    stopBtn.addEventListener('click', stopCamera);
  </script>
</body>
</html>
